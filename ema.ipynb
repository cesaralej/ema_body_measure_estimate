{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ema: e-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! git clone https://github.com/ultralytics/ultralytics.git\n",
    "#! cd ultralytics\n",
    "#! pip install -e '.[dev]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a variable for the YOLOv8n model\n",
    "model_path = 'yolo/yolov8n-pose.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! git clone git@github.com:facebookresearch/segment-anything.git\n",
    "#! cd segment-anything; pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SAM model checkpoint\n",
    "#! wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for focal points in the image\n",
    "NOSE = 0\n",
    "LEFT_EYE = 1\n",
    "RIGHT_EYE = 2\n",
    "LEFT_EAR = 3\n",
    "RIGHT_EAR = 4\n",
    "LEFT_SHOULDER = 5\n",
    "RIGHT_SHOULDER = 6\n",
    "LEFT_ELBOW = 7\n",
    "RIGHT_ELBOW = 8\n",
    "LEFT_WRIST = 9\n",
    "RIGHT_WRIST = 10\n",
    "LEFT_HIP = 11\n",
    "RIGHT_HIP = 12\n",
    "LEFT_KNEE = 13\n",
    "RIGHT_KNEE = 14\n",
    "LEFT_ANKLE = 15\n",
    "RIGHT_ANKLE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the cropped body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_inference(model_path, image):\n",
    "    model = YOLO(model_path)\n",
    "    results = model(image)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_body(model_path, demo_image):\n",
    "    results = yolo_inference(model_path, demo_image)\n",
    "\n",
    "    # Get the first detected person (assuming single person)\n",
    "    person = results[0].boxes.xyxy.cpu().numpy()[0]\n",
    "    xmin, ymin, xmax, ymax = int(person[0]), int(person[1]), int(person[2]), int(person[3])\n",
    "\n",
    "    loaded_image = cv2.imread(demo_image)\n",
    "    # Crop the image using the bounding box\n",
    "    cropped_img = loaded_image[ymin:ymax, xmin:xmax] \n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(results_crop):\n",
    "    result_keypoint = results_crop[0].keypoints.xy.cpu().numpy()[0]\n",
    "    return result_keypoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image, sam_model, boxes):\n",
    "  sam_model.set_image(image)\n",
    "  H, W, _ = image.shape\n",
    "  boxes_xyxy = boxes.xyxyn * torch.Tensor([W, H, W, H])\n",
    "\n",
    "  transformed_boxes = sam_model.transform.apply_boxes_torch(boxes_xyxy.cpu(), image.shape[:2])\n",
    "  masks, _, _ = sam_model.predict_torch(\n",
    "      point_coords = None,\n",
    "      point_labels = None,\n",
    "      boxes = transformed_boxes,\n",
    "      multimask_output = False,\n",
    "      )\n",
    "  return masks.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sam_segmentation(image, results_crop):\n",
    "    sam = sam_model_registry[\"default\"](checkpoint=\"legacy/segment-anything/sam_vit_h_4b8939.pth\")\n",
    "    predictor = SamPredictor(sam)\n",
    "    segmented_frame_masks = segment(image, predictor, boxes=results_crop[0].boxes)\n",
    "    return segmented_frame_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_mask(mask):\n",
    "    \"\"\"\n",
    "    Generate a black and white mask image.\n",
    "    \n",
    "    :param mask: The mask to be processed (PyTorch tensor or NumPy array).\n",
    "    :return: The binary mask image (NumPy array).\n",
    "    \"\"\"\n",
    "    # Convert the tensor to a NumPy array if it is a tensor\n",
    "    if torch.is_tensor(mask):\n",
    "        mask = mask.cpu().numpy()\n",
    "    \n",
    "    # Ensure the mask is 2D\n",
    "    if mask.ndim > 2:\n",
    "        mask = mask[0]\n",
    "\n",
    "    # Create a binary mask (white for the mask area, black otherwise)\n",
    "    binary_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "    binary_mask[mask > 0] = 255\n",
    "    \n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edge(image, start_x, start_y, left=True):\n",
    "    \"\"\"\n",
    "    Given a specific coordinate (start_x, start_y), go left or right until hitting a black pixel.\n",
    "    :param image: The mask image (numpy array).\n",
    "    :param start_x: The starting x-coordinate.\n",
    "    :param start_y: The starting y-coordinate.\n",
    "    :return: The x-coordinate of the edge.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the starting coordinate is within the image bounds\n",
    "    if start_y >= image.shape[0] or start_x >= image.shape[1]:\n",
    "        raise ValueError(\"Starting coordinates are outside the image bounds\")\n",
    "\n",
    "    if left:\n",
    "        # Start from the given coordinate and move left until a black pixel is found\n",
    "        for x in range(start_x, image.shape[1]):\n",
    "            if image[start_y, x] == 0:  # Assuming black pixel has value 0\n",
    "                return x - 1  # Return the first non-black pixel's x-coordinate\n",
    "    else:\n",
    "        # Start from the given coordinate and move right until a black pixel is found\n",
    "        for x in range(start_x, -1, -1):\n",
    "            if image[start_y, x] == 0:  # Assuming black pixel has value 0\n",
    "                return x + 1  # Return the first non-black pixel's x-coordinate\n",
    "\n",
    "    # If no black pixel is found, return 0 (the leftmost edge)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_per_cm(image, keypoints, height_cm, relative=False):\n",
    "    \"\"\"\n",
    "    Calculate the number of pixels per centimeter in the image.\n",
    "    \n",
    "    :param image: The mask image (NumPy array).\n",
    "    :param height_cm: The height in centimeters.\n",
    "    :return: The number of pixels per centimeter.\n",
    "    \"\"\"\n",
    "\n",
    "    ymax, _ = image.shape\n",
    "    # Get the y-coordinate of the top of the head\n",
    "    y_top_head = int(keypoints[LEFT_EYE][1])\n",
    "    # Get the y-coordinate of the bottom of the foot\n",
    "    y_bottom_foot = int(keypoints[LEFT_ANKLE][1])\n",
    "\n",
    "    # Calculate the height of the person in pixels\n",
    "    relative_height_pixels = y_bottom_foot- y_top_head\n",
    "    relative_height_cm = relative_height_pixels / height_cm\n",
    "\n",
    "    pixels_per_cm = ymax / height_cm\n",
    "\n",
    "    bias = 1.3\n",
    "\n",
    "    if relative:\n",
    "        return relative_height_cm * bias\n",
    "    else:\n",
    "        return pixels_per_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_perimeter(front_width, side_width):\n",
    "    \"\"\"\n",
    "    Calculate the circumference of an ellipse that circumscribes a rectangle.\n",
    "    \n",
    "    Parameters:\n",
    "    front_width (float): The width of the rectangle.\n",
    "    side_width (float): The height of the rectangle.\n",
    "    \n",
    "    Returns:\n",
    "    float: The circumference of the ellipse.\n",
    "    \"\"\"\n",
    "    # Calculate the semi-major and semi-minor axes\n",
    "    a = math.sqrt((front_width / 2)**2 + (side_width / 2)**2)\n",
    "    b = min(front_width / 2, side_width / 2)\n",
    "\n",
    "    # Calculate the perimeter using Ramanujan's approximation formula for an ellipse\n",
    "    perimeter = math.pi * (3 * (a + b) - math.sqrt((3 * a + b) * (a + 3 * b)))\n",
    "\n",
    "    return perimeter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shoulders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shoulder_length(image, keypoints):\n",
    "    left_shoulder_x, left_shoulder_y = keypoints[LEFT_SHOULDER]\n",
    "    ls_x, ls_y = int(left_shoulder_x), int(left_shoulder_y)\n",
    "    right_shoulder_x, right_shoulder_y = keypoints[RIGHT_SHOULDER]\n",
    "    rs_x, rs_y = int(right_shoulder_x), int(right_shoulder_y)\n",
    "    \n",
    "    # Find the edge\n",
    "    left_edge = find_edge(image, ls_x, ls_y)\n",
    "    distance_to_edge = left_edge - ls_x\n",
    "    right_edge = rs_x - distance_to_edge\n",
    "    difference =  left_edge - right_edge\n",
    "    shoulder_length = difference\n",
    "\n",
    "    return shoulder_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_waist(focuspoints, focuspoints_side, image, mask_side):\n",
    "    left_hip_x, left_hip_y = focuspoints[LEFT_HIP]\n",
    "    lh_x, lh_y  = int(left_hip_x), int(left_hip_y)\n",
    "    right_hip_x, right_hip_y = focuspoints[RIGHT_HIP]\n",
    "    rh_x, rh_y = int(right_hip_x), int(right_hip_y)\n",
    "    left_hip_side_x, left_hip_side_y = focuspoints_side[LEFT_HIP]\n",
    "    lhs_x, lhs_y = int(left_hip_side_x), int(left_hip_side_y)\n",
    "\n",
    "    # Get the measurement from the front of the chest\n",
    "    left_edge = find_edge(image, lh_x, lh_y)\n",
    "    right_edge = find_edge(image, rh_x, rh_y, left=False)\n",
    "    distance_to_left_edge = left_edge - lh_x\n",
    "    distance_to_right_edge = right_edge - rh_x\n",
    "    average_distance = (distance_to_left_edge + distance_to_right_edge) / 2\n",
    "    max_left = lh_x + average_distance\n",
    "    max_right = rh_x - average_distance\n",
    "    difference =  max_left - max_right\n",
    "    waist_front = difference\n",
    "    #print(f\"The person's waist width is {waist_front:.2f} cm\")\n",
    "\n",
    "    #Get the measurement from the side of the chest\n",
    "    right_side = find_edge(mask_side, lhs_x, lhs_y)\n",
    "    left_side = find_edge(mask_side, lhs_x, lhs_y, left=False)\n",
    "\n",
    "    waist_side = right_side - left_side\n",
    "    #print(f\"The person's Chest width is {shoulder_width:.2f} pixels\")\n",
    "\n",
    "    perimeter = ellipse_perimeter(waist_front, waist_side)\n",
    "    #print(f\"The approximate perimeter of the oval is: {perimeter:.2f}\")\n",
    "    return perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_chest(focuspoints, focuspoints_side, mask_side):\n",
    "    left_shoulder_x = focuspoints[LEFT_SHOULDER][0]\n",
    "    ls_x = int(left_shoulder_x)\n",
    "    right_shoulder_x = focuspoints[RIGHT_SHOULDER][0]\n",
    "    rs_x = int(right_shoulder_x)\n",
    "\n",
    "    left_shoulder_side_x, left_shoulder_side_y = focuspoints_side[LEFT_SHOULDER]\n",
    "    lss_x, lss_y = int(left_shoulder_side_x), int(left_shoulder_side_y)\n",
    "    left_elbow_y = focuspoints_side[LEFT_ELBOW][1]\n",
    "    le_y = int(left_elbow_y)\n",
    "\n",
    "    # Get the measurement from the front of the chest\n",
    "    shoulder_front =  ls_x - rs_x\n",
    "    #print(f\"The person's shoulder width is {shoulder_front:.2f} cm\")\n",
    "    \n",
    "    # Get the height between the shoulder and elbow\n",
    "    mid_shoulder_elbow_height = int(lss_y-((lss_y - le_y)/2))\n",
    "\n",
    "    #Get the measurement from the side of the chest\n",
    "    right_side = find_edge(mask_side, lss_x, mid_shoulder_elbow_height)\n",
    "    left_side = find_edge(mask_side, lss_x, mid_shoulder_elbow_height, left=False)\n",
    "\n",
    "    shoulder_width = right_side - left_side\n",
    "    #print(f\"The person's Chest width is {shoulder_width:.2f} pixels\")\n",
    "\n",
    "    perimeter = ellipse_perimeter(shoulder_front, shoulder_width)\n",
    "    #print(f\"The approximate perimeter of the oval is: {perimeter:.2f}\")\n",
    "    return perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_arm(focuspoints):\n",
    "    left_shoulder_x, left_shoulder_y = focuspoints[LEFT_SHOULDER]\n",
    "    ls_x, ls_y = int(left_shoulder_x), int(left_shoulder_y)\n",
    "    right_shoulder_x, right_shoulder_y = focuspoints[RIGHT_SHOULDER]\n",
    "    rs_x, rs_y = int(right_shoulder_x), int(right_shoulder_y)\n",
    "    left_wrist_x, left_wrist_y = focuspoints[LEFT_WRIST]\n",
    "    lw_x, lw_y = int(left_wrist_x), int(left_wrist_y)\n",
    "    right_wrist_x, right_wrist_y = focuspoints[RIGHT_WRIST]\n",
    "    rw_x, rw_y = int(right_wrist_x), int(right_wrist_y)\n",
    "\n",
    "    # Get distance from shoulder to wrist\n",
    "    left_distance = math.sqrt((lw_x - ls_x)**2 + (lw_y - ls_y)**2)\n",
    "    right_distance = math.sqrt((rw_x - rs_x)**2 + (rw_y - rs_y)**2) \n",
    "    distance = (left_distance + right_distance) / 2\n",
    "    return distance\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_length(focuspoints):\n",
    "    left_hip_x, left_hip_y = focuspoints[LEFT_HIP]\n",
    "    lh_x, lh_y = int(left_hip_x), int(left_hip_y)\n",
    "    right_hip_x, right_hip_y = focuspoints[RIGHT_HIP]\n",
    "    rh_x, rh_y = int(right_hip_x), int(right_hip_y)\n",
    "    left_shoulder_x, left_shoulder_y = focuspoints[LEFT_SHOULDER]\n",
    "    ls_x, ls_y = int(left_shoulder_x), int(left_shoulder_y)\n",
    "    right_shoulder_x, right_shoulder_y = focuspoints[RIGHT_SHOULDER]\n",
    "    rs_x, rs_y = int(right_shoulder_x), int(right_shoulder_y)\n",
    "\n",
    "    # Get distance from hip to ankle\n",
    "    left_distance = math.sqrt((ls_x - lh_x)**2 + (ls_y - lh_y)**2)\n",
    "    right_distance = math.sqrt((rs_x - rh_x)**2 + (rs_y - rh_y)**2) \n",
    "    distance = (left_distance + right_distance) / 2\n",
    "    bias = 1.2\n",
    "    return distance * bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_wrist(focuspoints, image_front):\n",
    "    left_wrist_x, left_wrist_y = focuspoints[LEFT_WRIST]\n",
    "    lw_x, lw_y = int(left_wrist_x), int(left_wrist_y)\n",
    "    right_wrist_x, right_wrist_y = focuspoints[RIGHT_WRIST]\n",
    "    rw_x, rw_y = int(right_wrist_x), int(right_wrist_y)\n",
    "\n",
    "    # Left wrist circumference\n",
    "    lw_left_edge = find_edge(image_front, lw_x, lw_y)\n",
    "    lw_right_edge = find_edge(image_front, lw_x, lw_y, left=False)\n",
    "    left_diameter = lw_left_edge - lw_right_edge\n",
    "\n",
    "    # Right wrist circumference\n",
    "    rw_left_edge = find_edge(image_front, rw_x, rw_y)\n",
    "    rw_right_edge = find_edge(image_front, rw_x, rw_y, left=False)\n",
    "    right_diameter = rw_left_edge - rw_right_edge\n",
    "\n",
    "    avr_diameter = (right_diameter + left_diameter) / 2\n",
    "\n",
    "    circumference = math.pi * avr_diameter\n",
    "    return circumference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shirt_size(size_chart, body_measurements):\n",
    "    \"\"\"\n",
    "    Determines the correct shirt size based on a size chart and body measurements.\n",
    "    Ensures no body measurement is below the corresponding size measurement.\n",
    "    \n",
    "    Parameters:\n",
    "    size_chart (list of dicts): A list where each dict represents a size and contains measurement information.\n",
    "                                Each dict should have keys like 'size', 'chest', 'waist', 'length', 'arm', etc.\n",
    "    body_measurements (dict): A dict containing the body measurements with keys corresponding to those in size_chart.\n",
    "    \n",
    "    Returns:\n",
    "    str: The size that best fits the body measurements or None if no suitable size is found.\n",
    "    \"\"\"\n",
    "    best_size = None\n",
    "    smallest_diff = float('inf')\n",
    "\n",
    "    for size_info in size_chart:\n",
    "        is_valid_size = True\n",
    "        total_diff = 0\n",
    "        \n",
    "        for measurement in body_measurements:\n",
    "            if measurement in size_info:\n",
    "                if body_measurements[measurement] > size_info[measurement]:\n",
    "                    is_valid_size = False\n",
    "                    #print(f\"Size {size_info['size']} is invalid for measurement {measurement}: {body_measurements[measurement]} < {size_info[measurement]}\")\n",
    "                    break\n",
    "                total_diff += abs(body_measurements[measurement] - size_info[measurement])\n",
    "        \n",
    "        if is_valid_size:\n",
    "            #print(f\"Size {size_info['size']} is valid with total diff: {total_diff}\")\n",
    "            if total_diff < smallest_diff:\n",
    "                smallest_diff = total_diff\n",
    "                best_size = size_info['size']\n",
    "    \n",
    "    return best_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema_inference(model_path, image_front):\n",
    "    print(\"Starting the EMA process...\")\n",
    "    print(\"Cropping the body...\")\n",
    "    cropped_img = crop_body(model_path, image_front)\n",
    "    print(\"Detecting pose focus points...\")\n",
    "    results_crop = yolo_inference(model_path, cropped_img)\n",
    "    result_keypoint = get_keypoints(results_crop)\n",
    "    print(\"Segmenting the body...\")\n",
    "    segmented_frame_masks = sam_segmentation(cropped_img, results_crop)\n",
    "    binary_mask = get_binary_mask(segmented_frame_masks[0][0])\n",
    "\n",
    "    return binary_mask, result_keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask(mask, focalpoints, file_name):\n",
    "    body_coords = {part: focalpoints[part] for part in range(17)}\n",
    "\n",
    "    # make body_coords a list of tuples\n",
    "    body_coords_t = [(x, y) for x, y in body_coords.values()]\n",
    "\n",
    "\n",
    "    # Draw a point at the left shoulder coordinates\n",
    "    point_color = (255, 0, 0)  # Red color in RGB\n",
    "    point_radius = 5\n",
    "    point_thickness = -1  # Thickness of -1 px will fill the circle\n",
    "\n",
    "    people_mask = cv2.convertScaleAbs(mask)\n",
    "    mask_image_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Draw the point on the image\n",
    "    for x, y in body_coords_t:\n",
    "        cv2.circle(mask_image_bgr, (int(x), int(y)), point_radius, point_color, point_thickness)\n",
    "\n",
    "    #save the result image\n",
    "    cv2.imwrite(file_name, cv2.cvtColor(mask_image_bgr, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(model_path, image_front, image_side, height_cm, size_chart):\n",
    "    print(\"Starting the EMA process...\")\n",
    "\n",
    "    print(\"Calculating front focal points...\")\n",
    "    binary_mask, result_keypoint = ema_inference(model_path, image_front)\n",
    "\n",
    "    print(\"Calculating side focal points...\")\n",
    "    binary_mask_side, result_keypoint_side = ema_inference(model_path, image_side)\n",
    "    \n",
    "    pixels_per_cm = get_pixels_per_cm(binary_mask, result_keypoint, height_cm, relative=True)\n",
    "    chest = round(measure_chest(result_keypoint, result_keypoint_side, binary_mask_side)/pixels_per_cm,2)\n",
    "    waist = round(measure_waist(result_keypoint, result_keypoint_side, binary_mask, binary_mask_side)/pixels_per_cm,2)\n",
    "    arm = round(measure_arm(result_keypoint)/pixels_per_cm,2)\n",
    "    length = round(measure_length(result_keypoint)/pixels_per_cm,2)\n",
    "    wrist = round(measure_wrist(result_keypoint, binary_mask)/pixels_per_cm,2)\n",
    "    shoulders = round(get_shoulder_length(binary_mask, result_keypoint)/pixels_per_cm,2)\n",
    "    body_measurements = {\"shoulders\": shoulders, \"waist\": waist, \"length\": length, \"arm\": arm, \"chest\": chest, \"wrist\": wrist, \"Px/cm\": pixels_per_cm}\n",
    "    shirt_size = find_shirt_size(size_chart, body_measurements)\n",
    "    print(f\"The number of pixels per centimeter is: {pixels_per_cm:.2f}\")\n",
    "    print(f\"Shoulders: {shoulders:.2f} cm\")\n",
    "    print(f\"Upper body length: {length:.2f} cm\")\n",
    "    print(f\"Waist: {waist:.2f} cm\")\n",
    "    print(f\"Arm length: {arm:.2f} cm\")\n",
    "    print(f\"Chest: {chest:.2f} cm\")\n",
    "    #print(f\"wrist: {wrist:.2f} cm\\n\")\n",
    "    print(f\"The recommended shirt size for {demo_image.split('/')[-1].split('.')[0]} is: {shirt_size}\")\n",
    "    result_file_name = demo_image.split('/')[-1].split('.')[0] + '_result.jpg'\n",
    "    save_mask(binary_mask, result_keypoint, result_file_name)\n",
    "    save_mask(binary_mask_side, result_keypoint_side, result_file_name.split('.')[0] + '_side.jpg')\n",
    "    body_measurements = {\"shoulders\": shoulders, \"waist\": waist, \"length\": length, \"arm\": arm, \"chest\": chest, \"wrist\": wrist, \"Px/cm\": pixels_per_cm, \"shirt_size\": shirt_size}\n",
    "    return body_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_image = f'data/demo.jpeg' # replace with the path to the image\n",
    "demo_image_side = f'data/demo_side.jpeg' # replace with the path to the image side view\n",
    "demo_height = 175 # replace with the height of the person in centimeters\n",
    "size_chart = [\n",
    "    {'size': 'S', 'chest': 88, 'waist': 88, 'length': 70, 'arm': 62},\n",
    "    {'size': 'M', 'chest': 94, 'waist': 94, 'length': 71, 'arm': 63},\n",
    "    {'size': 'L', 'chest': 101, 'waist': 101, 'length': 72, 'arm': 64},\n",
    "    {'size': 'XL', 'chest': 107, 'waist': 107, 'length': 75 , 'arm': 65}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = ema(model_path, demo_image, demo_image_side, demo_height, size_chart)\n",
    "print(f\"The recommended shirt size for {demo_image.split('/')[-1].split('.')[0]} is: {test_results['shirt_size']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ema_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
